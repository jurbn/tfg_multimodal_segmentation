\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\citation{NIPS2012_c399862d}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introducción}{2}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:introduction}{{1}{2}{Introducción}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivación}{2}{section.1.1}\protected@file@percent }
\newlabel{sec:motivation}{{1.1}{2}{Motivación}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Objetivos}{2}{section.1.2}\protected@file@percent }
\newlabel{sec:objectives}{{1.2}{2}{Objetivos}{section.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Trabajos Relacionados}{2}{section.1.3}\protected@file@percent }
\newlabel{sec:related_work}{{1.3}{2}{Trabajos Relacionados}{section.1.3}{}}
\citation{ronneberger2015unetconvolutionalnetworksbiomedical}
\citation{huang2024mmaunetmultimodalasymmetricunet}
\citation{marinov2023mirrorunetmarryingmultimodal}
\citation{girshick2015fastrcnn}
\citation{he2018maskrcnn}
\citation{vaswani2023attentionneed}
\citation{radford2018improving}
\citation{devlin2019bertpretrainingdeepbidirectional}
\citation{raffel2023exploringlimitstransferlearning}
\citation{dosovitskiy2021imageworth16x16words}
\citation{carion2020endtoendobjectdetectiontransformers}
\citation{xie2021segformersimpleefficientdesign}
\citation{strudel2021segmentertransformersemanticsegmentation}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Redes Convolucionales}{3}{subsection.1.3.1}\protected@file@percent }
\newlabel{subsec:cnn}{{1.3.1}{3}{Redes Convolucionales}{subsection.1.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}UNets}{3}{subsection.1.3.2}\protected@file@percent }
\newlabel{subsec:unets}{{1.3.2}{3}{UNets}{subsection.1.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Arquitectura de un modelo \texttt  {UNet}}}{3}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:unet-architecture}{{1.1}{3}{Arquitectura de un modelo \texttt {UNet}}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Mask R-CNN}{3}{subsection.1.3.3}\protected@file@percent }
\newlabel{subsec:maskrcnn}{{1.3.3}{3}{Mask R-CNN}{subsection.1.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}Transformers}{3}{subsection.1.3.4}\protected@file@percent }
\newlabel{subsec:transformers}{{1.3.4}{3}{Transformers}{subsection.1.3.4}{}}
\citation{sheepcounter-odziz_dataset}
\citation{birdsai-duqdg_dataset}
\citation{guillen-garde_detection_2021}
\citation{XU2024103732}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Arquitectura de un modelo \texttt  {Mask R-CNN}}}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:mask-rcnn-architecture}{{1.2}{4}{Arquitectura de un modelo \texttt {Mask R-CNN}}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.5}Monitorización de Animales}{4}{subsection.1.3.5}\protected@file@percent }
\newlabel{subsec:animal_monitoring}{{1.3.5}{4}{Monitorización de Animales}{subsection.1.3.5}{}}
\citation{noaa_alaska_fisheries_2021}
\citation{uav_waterfowl_thermal_2021}
\citation{haucke2021exploitingdepthinformationwildlife}
\citation{haucke2021exploitingdepthinformationwildlife}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Datos}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:data}{{2}{5}{Datos}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Datasets Disponibles}{5}{section.2.1}\protected@file@percent }
\newlabel{sec:available_datasets}{{2.1}{5}{Datasets Disponibles}{section.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Lindenthal Camera Traps Dataset}{6}{section.2.2}\protected@file@percent }
\newlabel{sec:lindenthal_dataset}{{2.2}{6}{Lindenthal Camera Traps Dataset}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Ejemplo de una pareja \texttt  {IR}-\texttt  {D} del \textit  {dataset} \texttt  {Lindenthal Camera Traps}}}{6}{figure.caption.4}\protected@file@percent }
\newlabel{fig:base-data-lindenthal}{{2.1}{6}{Ejemplo de una pareja \texttt {IR}-\texttt {D} del \textit {dataset} \texttt {Lindenthal Camera Traps}}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Desglose del \textit  {Dataset}}{6}{subsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Desglose de la frecuencia de aparición de cada categoría en el dataset}}{7}{figure.caption.5}\protected@file@percent }
\newlabel{fig:dataset-breakdown}{{2.2}{7}{Desglose de la frecuencia de aparición de cada categoría en el dataset}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Ejemplo de una pareja \texttt  {IR}-\texttt  {D} del \textit  {dataset} \texttt  {Lindenthal Camera Traps}}}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:tagged-example}{{2.3}{7}{Ejemplo de una pareja \texttt {IR}-\texttt {D} del \textit {dataset} \texttt {Lindenthal Camera Traps}}{figure.caption.6}{}}
\citation{zhang2023cmxcrossmodalfusionrgbx}
\citation{zhang2023cmxcrossmodalfusionrgbx}
\citation{zhang2023cmxcrossmodalfusionrgbx}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Cross Modal Fusion}{8}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:cmx}{{3}{8}{Cross Modal Fusion}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Descripción del Modelo}{8}{section.3.1}\protected@file@percent }
\newlabel{sec:cmx_description}{{3.1}{8}{Descripción del Modelo}{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Arquitectura propuesta por \cite  {zhang2023cmxcrossmodalfusionrgbx}}}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:cmx-architecture}{{3.1}{8}{Arquitectura propuesta por \cite {zhang2023cmxcrossmodalfusionrgbx}}{figure.caption.7}{}}
\citation{gupta2014learningrichfeaturesrgbd}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Técnicas de Pre-Procesado}{9}{section.3.2}\protected@file@percent }
\newlabel{sec:preprocessing_techniques}{{3.2}{9}{Técnicas de Pre-Procesado}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}HHA Encoding}{9}{subsection.3.2.1}\protected@file@percent }
\newlabel{subsec:hha_encoding}{{3.2.1}{9}{HHA Encoding}{subsection.3.2.1}{}}
\citation{eitel2015multimodaldeeplearningrobust}
\citation{eitel2015multimodaldeeplearningrobust}
\newlabel{fig:depth-base-hha}{{3.2a}{10}{Imagen de profundidad base}{figure.caption.8}{}}
\newlabel{sub@fig:depth-base-hha}{{a}{10}{Imagen de profundidad base}{figure.caption.8}{}}
\newlabel{fig:hha-colorization}{{3.2b}{10}{Profundidad colorizada con \texttt {HHA}}{figure.caption.8}{}}
\newlabel{sub@fig:hha-colorization}{{b}{10}{Profundidad colorizada con \texttt {HHA}}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Comparación entre la imagen de profundidad base y la imagen de profundidad codificada con \texttt  {HHA}}}{10}{figure.caption.8}\protected@file@percent }
\newlabel{fig:hha-comparison}{{3.2}{10}{Comparación entre la imagen de profundidad base y la imagen de profundidad codificada con \texttt {HHA}}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Colorizacón Jet}{10}{subsection.3.2.2}\protected@file@percent }
\newlabel{subsec:jet_colorization}{{3.2.2}{10}{Colorizacón Jet}{subsection.3.2.2}{}}
\citation{eitel2015multimodaldeeplearningrobust}
\newlabel{fig:depth-base-jet}{{3.3a}{11}{Imagen de profundidad base}{figure.caption.9}{}}
\newlabel{sub@fig:depth-base-jet}{{a}{11}{Imagen de profundidad base}{figure.caption.9}{}}
\newlabel{fig:jet-colorization}{{3.3b}{11}{Profundidad colorizada con \textit {Jet}}{figure.caption.9}{}}
\newlabel{sub@fig:jet-colorization}{{b}{11}{Profundidad colorizada con \textit {Jet}}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Comparación entre la imagen de profundidad base y la imagen de profundidad codificada con Jet}}{11}{figure.caption.9}\protected@file@percent }
\newlabel{fig:jet-comparison}{{3.3}{11}{Comparación entre la imagen de profundidad base y la imagen de profundidad codificada con Jet}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Colorización por Distancia}{11}{subsection.3.2.3}\protected@file@percent }
\newlabel{subsec:distance_colorization}{{3.2.3}{11}{Colorización por Distancia}{subsection.3.2.3}{}}
\newlabel{fig:depth-base-distance}{{3.4a}{11}{Imagen de profundidad base}{figure.caption.10}{}}
\newlabel{sub@fig:depth-base-distance}{{a}{11}{Imagen de profundidad base}{figure.caption.10}{}}
\newlabel{fig:distance-colorization}{{3.4b}{11}{Profundidad colorizada por distancia}{figure.caption.10}{}}
\newlabel{sub@fig:distance-colorization}{{b}{11}{Profundidad colorizada por distancia}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Comparación entre la imagen de profundidad base y la imagen de profundidad codificada con Jet}}{11}{figure.caption.10}\protected@file@percent }
\newlabel{fig:distance-comparison}{{3.4}{11}{Comparación entre la imagen de profundidad base y la imagen de profundidad codificada con Jet}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Normales}{11}{subsection.3.2.4}\protected@file@percent }
\newlabel{subsec:normals}{{3.2.4}{11}{Normales}{subsection.3.2.4}{}}
\newlabel{fig:depth-base-distance}{{3.5a}{12}{Imagen de profundidad base}{figure.caption.11}{}}
\newlabel{sub@fig:depth-base-distance}{{a}{12}{Imagen de profundidad base}{figure.caption.11}{}}
\newlabel{fig:normals-colorization}{{3.5b}{12}{Profundidad colorizada por normales}{figure.caption.11}{}}
\newlabel{sub@fig:normals-colorization}{{b}{12}{Profundidad colorizada por normales}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Comparación entre la imagen de profundidad base y la imagen de profundidad codificada con normales}}{12}{figure.caption.11}\protected@file@percent }
\newlabel{fig:normals-comparison}{{3.5}{12}{Comparación entre la imagen de profundidad base y la imagen de profundidad codificada con normales}{figure.caption.11}{}}
\newlabel{eq:normals}{{3.1}{12}{Normales}{equation.3.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Entrenamiento}{12}{section.3.3}\protected@file@percent }
\newlabel{sec:cmx_training}{{3.3}{12}{Entrenamiento}{section.3.3}{}}
\citation{xie2021segformersimpleefficientdesign}
\citation{zhang2023cmxcrossmodalfusionrgbx}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Comparación de la aplicación de \textit  {modality dropout}}}{13}{table.caption.12}\protected@file@percent }
\newlabel{tab:modality_dropout_comparison}{{3.1}{13}{Comparación de la aplicación de \textit {modality dropout}}{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Implementación}{13}{subsection.3.3.1}\protected@file@percent }
\newlabel{subsec:implementation}{{3.3.1}{13}{Implementación}{subsection.3.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Comparación de Técnicas}{14}{section.3.4}\protected@file@percent }
\newlabel{subsec:cmx_techniques_comparison}{{3.4}{14}{Comparación de Técnicas}{section.3.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces IoU de las técnicas de pre-procesado propuestas}}{14}{table.caption.13}\protected@file@percent }
\newlabel{tab:techniques_comparison}{{3.2}{14}{IoU de las técnicas de pre-procesado propuestas}{table.caption.13}{}}
\newlabel{eq:iou}{{3.2}{14}{Comparación de Técnicas}{equation.3.4.2}{}}
\citation{yin2024dformerrethinkingrgbdrepresentation}
\citation{yin2024dformerrethinkingrgbdrepresentation}
\citation{yin2024dformerrethinkingrgbdrepresentation}
\citation{yin2024dformerrethinkingrgbdrepresentation}
\citation{yin2024dformerrethinkingrgbdrepresentation}
\citation{yin2024dformerrethinkingrgbdrepresentation}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}DFormer}{15}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:dformer}{{4}{15}{DFormer}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Descripción del Modelo}{15}{section.4.1}\protected@file@percent }
\newlabel{sec:dformer_description}{{4.1}{15}{Descripción del Modelo}{section.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Arquitectura propuesta por \cite  {yin2024dformerrethinkingrgbdrepresentation}}}{15}{figure.caption.14}\protected@file@percent }
\newlabel{fig:dformer-architecture}{{4.1}{15}{Arquitectura propuesta por \cite {yin2024dformerrethinkingrgbdrepresentation}}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}El pre-entrenamiento}{15}{section.4.2}\protected@file@percent }
\newlabel{sec:dformer_pretraining}{{4.2}{15}{El pre-entrenamiento}{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Bloques \texttt  {RGB-D} propuestos por \cite  {yin2024dformerrethinkingrgbdrepresentation}}}{16}{figure.caption.15}\protected@file@percent }
\newlabel{fig:dformer-blocks}{{4.2}{16}{Bloques \texttt {RGB-D} propuestos por \cite {yin2024dformerrethinkingrgbdrepresentation}}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Resultados}{16}{section.4.3}\protected@file@percent }
\newlabel{sec:dformer_results}{{4.3}{16}{Resultados}{section.4.3}{}}
\citation{strudel2021segmentertransformersemanticsegmentation}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Resultados}{17}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{17}{Resultados}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Cross Modal Fusion}{17}{section.5.1}\protected@file@percent }
\newlabel{sec:cmx_results}{{5.1}{17}{Cross Modal Fusion}{section.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Comparación de los resultados de segmentación entre un modelo \texttt  {SegFormer} básico, \texttt  {CMX} entrenado tan solo en la modalidad \texttt  {IR} y \texttt  {CMX} entrenado en pares \texttt  {IR-D}}}{17}{table.caption.16}\protected@file@percent }
\newlabel{tab:segformer_cmx_comparison}{{5.1}{17}{Comparación de los resultados de segmentación entre un modelo \texttt {SegFormer} básico, \texttt {CMX} entrenado tan solo en la modalidad \texttt {IR} y \texttt {CMX} entrenado en pares \texttt {IR-D}}{table.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Resultados de la segmentación}}{18}{figure.caption.17}\protected@file@percent }
\newlabel{fig:segmentation-example}{{5.1}{18}{Resultados de la segmentación}{figure.caption.17}{}}
\citation{haucke2021exploitingdepthinformationwildlife}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusiones y trabajo futuro}{19}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Conclusiones}{19}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Trabajo futuro}{19}{section.6.2}\protected@file@percent }
\bibdata{refs.bib}
\newlabel{app:appendix_a}{{6.2}{20}{Trabajo futuro}{section.6.2}{}}
\bibcite{NIPS2012_c399862d}{1}
\bibcite{ronneberger2015unetconvolutionalnetworksbiomedical}{2}
\bibcite{huang2024mmaunetmultimodalasymmetricunet}{3}
\bibcite{marinov2023mirrorunetmarryingmultimodal}{4}
\bibcite{girshick2015fastrcnn}{5}
\bibcite{he2018maskrcnn}{6}
\bibcite{vaswani2023attentionneed}{7}
\bibcite{radford2018improving}{8}
\bibcite{devlin2019bertpretrainingdeepbidirectional}{9}
\bibcite{raffel2023exploringlimitstransferlearning}{10}
\bibcite{dosovitskiy2021imageworth16x16words}{11}
\bibcite{carion2020endtoendobjectdetectiontransformers}{12}
\bibcite{xie2021segformersimpleefficientdesign}{13}
\bibcite{strudel2021segmentertransformersemanticsegmentation}{14}
\bibcite{sheepcounter-odziz_dataset}{15}
\bibcite{birdsai-duqdg_dataset}{16}
\bibcite{guillen-garde_detection_2021}{17}
\bibcite{XU2024103732}{18}
\bibcite{noaa_alaska_fisheries_2021}{19}
\bibcite{uav_waterfowl_thermal_2021}{20}
\bibcite{haucke2021exploitingdepthinformationwildlife}{21}
\bibcite{zhang2023cmxcrossmodalfusionrgbx}{22}
\bibcite{gupta2014learningrichfeaturesrgbd}{23}
\bibcite{eitel2015multimodaldeeplearningrobust}{24}
\bibcite{yin2024dformerrethinkingrgbdrepresentation}{25}
\bibstyle{IEEEtran}
\gdef \@abspage@last{24}
