@misc{gupta2014learningrichfeaturesrgbd,
      title={Learning Rich Features from RGB-D Images for Object Detection and Segmentation}, 
      author={Saurabh Gupta and Ross Girshick and Pablo Arbeláez and Jitendra Malik},
      year={2014},
      eprint={1407.5736},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1407.5736}, 
}
@misc{eitel2015multimodaldeeplearningrobust,
      title={Multimodal Deep Learning for Robust RGB-D Object Recognition}, 
      author={Andreas Eitel and Jost Tobias Springenberg and Luciano Spinello and Martin Riedmiller and Wolfram Burgard},
      year={2015},
      eprint={1507.06821},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1507.06821}, 
}
@misc{zhang2023cmxcrossmodalfusionrgbx,
      title={CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with Transformers}, 
      author={Jiaming Zhang and Huayao Liu and Kailun Yang and Xinxin Hu and Ruiping Liu and Rainer Stiefelhagen},
      year={2023},
      eprint={2203.04838},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2203.04838}, 
}
@misc{haucke2021exploitingdepthinformationwildlife,
      title={Exploiting Depth Information for Wildlife Monitoring}, 
      author={Timm Haucke and Volker Steinhage},
      year={2021},
      eprint={2102.05607},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2102.05607}, 
}
@misc{yin2024dformerrethinkingrgbdrepresentation,
      title={DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation}, 
      author={Bowen Yin and Xuying Zhang and Zhongyu Li and Li Liu and Ming-Ming Cheng and Qibin Hou},
      year={2024},
      eprint={2309.09668},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.09668}, 
}
@misc{ronneberger2015unetconvolutionalnetworksbiomedical,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1505.04597}, 
}
@misc{huang2024mmaunetmultimodalasymmetricunet,
      title={MMA-UNet: A Multi-Modal Asymmetric UNet Architecture for Infrared and Visible Image Fusion}, 
      author={Jingxue Huang and Xilai Li and Tianshu Tan and Xiaosong Li and Tao Ye},
      year={2024},
      eprint={2404.17747},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.17747}, 
}
@misc{marinov2023mirrorunetmarryingmultimodal,
      title={Mirror U-Net: Marrying Multimodal Fission with Multi-task Learning for Semantic Segmentation in Medical Imaging}, 
      author={Zdravko Marinov and Simon Reiß and David Kersting and Jens Kleesiek and Rainer Stiefelhagen},
      year={2023},
      eprint={2303.07126},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2303.07126}, 
}
@misc{girshick2015fastrcnn,
      title={Fast R-CNN}, 
      author={Ross Girshick},
      year={2015},
      eprint={1504.08083},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1504.08083}, 
}
@misc{he2018maskrcnn,
      title={Mask R-CNN}, 
      author={Kaiming He and Georgia Gkioxari and Piotr Dollár and Ross Girshick},
      year={2018},
      eprint={1703.06870},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1703.06870}, 
}
@inproceedings{NIPS2012_c399862d,
      author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
      booktitle = {Advances in Neural Information Processing Systems},
      editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
      pages = {},
      publisher = {Curran Associates, Inc.},
      title = {ImageNet Classification with Deep Convolutional Neural Networks},
      url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
      volume = {25},
      year = {2012}
}
@article{https://doi.org/10.1111/j.1469-8137.1912.tb05611.x,
      author = {Jaccard, Paul},
      title = {THE DISTRIBUTION OF THE FLORA IN THE ALPINE ZONE.},
      journal = {New Phytologist},
      volume = {11},
      number = {2},
      pages = {37-50},
      doi = {https://doi.org/10.1111/j.1469-8137.1912.tb05611.x},
      url = {https://nph.onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8137.1912.tb05611.x},
      eprint = {https://nph.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-8137.1912.tb05611.x},
      year = {1912}
}
@misc{xie2021segformersimpleefficientdesign,
      title={SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers}, 
      author={Enze Xie and Wenhai Wang and Zhiding Yu and Anima Anandkumar and Jose M. Alvarez and Ping Luo},
      year={2021},
      eprint={2105.15203},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2105.15203}, 
}
@misc{noaa_alaska_fisheries_2021,
  author       = {{Alaska Fisheries Science Center}},
  title        = {A Dataset for Machine Learning Algorithm Development},
  year         = {2021},
  url          = {https://www.fisheries.noaa.gov/inport/item/63322}
}
@dataset{uav_waterfowl_thermal_2021,
  author       = {Hu, Qiao and Smith, Jacob and Woldt, Wayne and Tang, Zhenghong},
  title        = {UAV-derived waterfowl thermal imagery dataset},
  year         = {2021},
  publisher    = {Mendeley Data},
  version      = {V4},
  doi          = {10.17632/46k66mz9sz.4},
  url          = {https://doi.org/10.17632/46k66mz9sz.4}
}
@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}
@article{radford2018improving,
      added-at = {2020-07-14T16:37:42.000+0200},
      author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
      biburl = {https://www.bibsonomy.org/bibtex/273ced32c0d4588eb95b6986dc2c8147c/jonaskaiser},
      interhash = {5c343ed9a31ac52fd17a898f72af228f},
      intrahash = {73ced32c0d4588eb95b6986dc2c8147c},
      keywords = {final thema:transformer},
      timestamp = {2020-07-14T16:49:42.000+0200},
      title = {Improving language understanding by generative pre-training},
      year = 2018
}
@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}
@misc{raffel2023exploringlimitstransferlearning,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2023},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.10683}, 
}
@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}
@misc{carion2020endtoendobjectdetectiontransformers,
      title={End-to-End Object Detection with Transformers}, 
      author={Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
      year={2020},
      eprint={2005.12872},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2005.12872}, 
}
@misc{strudel2021segmentertransformersemanticsegmentation,
      title={Segmenter: Transformer for Semantic Segmentation}, 
      author={Robin Strudel and Ricardo Garcia and Ivan Laptev and Cordelia Schmid},
      year={2021},
      eprint={2105.05633},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2105.05633}, 
}
@article{XU2024103732,
      title = {A review of deep learning techniques for detecting animals in aerial and satellite images},
      journal = {International Journal of Applied Earth Observation and Geoinformation},
      volume = {128},
      pages = {103732},
      year = {2024},
      issn = {1569-8432},
      doi = {https://doi.org/10.1016/j.jag.2024.103732},
      url = {https://www.sciencedirect.com/science/article/pii/S1569843224000864},
      author = {Zeyu Xu and Tiejun Wang and Andrew K. Skidmore and Richard Lamprey},
      keywords = {Biodiversity, Wildlife, Livestock, Remote sensing, Artificial intelligence, Object detection},
      abstract = {Deep learning is an effective machine learning method that in recent years has been successfully applied to detect and monitor species population in remotely sensed data. This study aims to provide a systematic literature review of current applications of deep learning methods for animal detection in aerial and satellite images. We categorized methods in collated publications into image level, point level, bounding-box level, instance segmentation level, and specific information level. The statistical results show that YOLO, Faster R-CNN, U-Net and ResNet are the most used neural network structures. The main challenges associated with the use of these deep learning methods are imbalanced datasets, small samples, small objects, image annotation methods, image background, animal counting, model accuracy assessment, and uncertainty estimation. We explored possible solutions include the selection of sample annotation methods, optimizing positive or negative samples, using weakly and self-supervised learning methods, selecting or developing more suitable network structures. Future research trends we identified are video-based detection, very high-resolution satellite image-based detection, multiple species detection, new annotation methods, and the development of specialized network structures and large foundation models. We discussed existing research attempts as well as personal perspectives on these possible solutions and future trends.}
}
@misc{sheepcounter-odziz_dataset,
      title = { SheepCounter Dataset },
      type = { Open Source Dataset },
      author = { Godfrey Nolan },
      howpublished = { \url{ https://universe.roboflow.com/sjy/sheepcounter-odziz } },
      url = { https://universe.roboflow.com/sjy/sheepcounter-odziz },
      journal = { Roboflow Universe },
      publisher = { Roboflow },
      year = { 2024 },
      month = { sep },
      note = { visited on 2025-01-20 },
}
@misc{birdsai-duqdg_dataset,
      title = { BIRDSAI Dataset },
      type = { Open Source Dataset },
      author = { BIRDSAI },
      howpublished = { \url{ https://universe.roboflow.com/birdsai/birdsai-duqdg } },
      url = { https://universe.roboflow.com/birdsai/birdsai-duqdg },
      journal = { Roboflow Universe },
      publisher = { Roboflow },
      year = { 2022 },
      month = { jun },
      note = { visited on 2025-01-20 },
}
@article{guillen-garde_detection_2021,
      author       = {Guillén-Garde, Sara and López-Nicolás, Gonzalo and Aragüés, Rosario},
      title        = {Detection and tracking of livestock herds from aerial video sequences},
      journal      = {Instituto de Investigación en Ingeniería de Aragón, Universidad de Zaragoza, Spain},
      year         = {2021},
      email        = {raragues@unizar.es, gonlopez@unizar.es}
}

