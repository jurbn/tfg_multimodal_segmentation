{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dir to ../\n",
    "import os\n",
    "import sys\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(\"src/cmx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition\n",
    "import numpy as np\n",
    "def get_class_colors(*args):\n",
    "        def uint82bin(n, count=8):\n",
    "            \"\"\"returns the binary of integer n, count refers to amount of bits\"\"\"\n",
    "            return ''.join([str((n >> y) & 1) for y in range(count - 1, -1, -1)])\n",
    "\n",
    "        N = 41\n",
    "        cmap = np.zeros((N, 3), dtype=np.uint8)\n",
    "        for i in range(N):\n",
    "            r, g, b = 0, 0, 0\n",
    "            id = i\n",
    "            for j in range(7):\n",
    "                str_id = uint82bin(id)\n",
    "                r = r ^ (np.uint8(str_id[-1]) << (7 - j))\n",
    "                g = g ^ (np.uint8(str_id[-2]) << (7 - j))\n",
    "                b = b ^ (np.uint8(str_id[-3]) << (7 - j))\n",
    "                id = id >> 3\n",
    "            cmap[i, 0] = r\n",
    "            cmap[i, 1] = g\n",
    "            cmap[i, 2] = b\n",
    "        class_colors = cmap.tolist()\n",
    "        return class_colors\n",
    "\n",
    "def color_mask(mask, colors):\n",
    "    \"\"\"\n",
    "    Assign colors to a mask image.\n",
    "    Args:\n",
    "        mask: a PIL Image with a single channel\n",
    "        colors: a list of RGB colors\n",
    "    \"\"\"\n",
    "    colored_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(len(colors)):\n",
    "        colored_mask[mask == i] = colors[i]\n",
    "    return colored_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m22 01:40:20 \u001b[0mUsing backbone: Segformer-B0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/miniforge3/envs/tfg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jorge/miniforge3/envs/tfg/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "\u001b[32m22 01:40:22 \u001b[0mUsing MLP Decoder\n",
      "\u001b[32m22 01:40:22 \u001b[0mLoading pretrained model: /media/jorge/HDD/TFG/pretrained/segformers/mit_b0.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mit_b0 has 10795720 parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/jorge/HDD/TFG/src/cmx/models/encoders/dual_segformer.py:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  raw_state_dict = torch.load(model_file, map_location=torch.device('cpu'))\n",
      "\u001b[32m22 01:40:23 \u001b[0mLoad model, Time usage:\n",
      "\tIO: 0.7322523593902588, initialize parameters: 0.014470100402832031\n",
      "\u001b[32m22 01:40:23 \u001b[0mIniting weights ...\n",
      "\u001b[32m22 01:40:23 \u001b[0mLoading pretrained model: out/log_lindenthal-camera-traps_mit_b0_pretrained_jet_dropout/checkpoint/epoch-last.pth\n",
      "\u001b[32m22 01:40:30 \u001b[0mLoad model, Time usage:\n",
      "\tIO: 7.257330894470215, initialize parameters: 0.004538536071777344\n",
      "\u001b[32m22 01:40:30 \u001b[0mIniting weights ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (backbone): mit_b0(\n",
       "    (patch_embed1): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed2): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed3): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed4): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (extra_patch_embed1): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (extra_patch_embed2): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (extra_patch_embed3): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (extra_patch_embed4): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (block1): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (kv): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (kv): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "        (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "    (extra_block1): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (kv): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (kv): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "        (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "    (block2): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (extra_block2): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (block3): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (kv): Linear(in_features=160, out_features=320, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (kv): Linear(in_features=160, out_features=320, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm3): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "    (extra_block3): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (kv): Linear(in_features=160, out_features=320, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (kv): Linear(in_features=160, out_features=320, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra_norm3): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
       "    (block4): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.086)\n",
       "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "    (extra_block4): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.086)\n",
       "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "    (FRMs): ModuleList(\n",
       "      (0): FeatureRectifyModule(\n",
       "        (channel_weights): ChannelWeights(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (spatial_weights): SpatialWeights(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): FeatureRectifyModule(\n",
       "        (channel_weights): ChannelWeights(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (spatial_weights): SpatialWeights(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): FeatureRectifyModule(\n",
       "        (channel_weights): ChannelWeights(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=640, out_features=320, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (spatial_weights): SpatialWeights(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(160, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): FeatureRectifyModule(\n",
       "        (channel_weights): ChannelWeights(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (spatial_weights): SpatialWeights(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (FFMs): ModuleList(\n",
       "      (0): FeatureFusionModule(\n",
       "        (cross): CrossPath(\n",
       "          (channel_proj1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (channel_proj2): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "          (cross_attn): CrossAttention(\n",
       "            (kv1): Linear(in_features=32, out_features=64, bias=False)\n",
       "            (kv2): Linear(in_features=32, out_features=64, bias=False)\n",
       "          )\n",
       "          (end_proj1): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (end_proj2): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (channel_emb): ChannelEmbed(\n",
       "          (residual): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (channel_embed): Sequential(\n",
       "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): FeatureFusionModule(\n",
       "        (cross): CrossPath(\n",
       "          (channel_proj1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (channel_proj2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "          (cross_attn): CrossAttention(\n",
       "            (kv1): Linear(in_features=64, out_features=128, bias=False)\n",
       "            (kv2): Linear(in_features=64, out_features=128, bias=False)\n",
       "          )\n",
       "          (end_proj1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (end_proj2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (channel_emb): ChannelEmbed(\n",
       "          (residual): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (channel_embed): Sequential(\n",
       "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): FeatureFusionModule(\n",
       "        (cross): CrossPath(\n",
       "          (channel_proj1): Linear(in_features=160, out_features=320, bias=True)\n",
       "          (channel_proj2): Linear(in_features=160, out_features=320, bias=True)\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "          (cross_attn): CrossAttention(\n",
       "            (kv1): Linear(in_features=160, out_features=320, bias=False)\n",
       "            (kv2): Linear(in_features=160, out_features=320, bias=False)\n",
       "          )\n",
       "          (end_proj1): Linear(in_features=320, out_features=160, bias=True)\n",
       "          (end_proj2): Linear(in_features=320, out_features=160, bias=True)\n",
       "          (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (channel_emb): ChannelEmbed(\n",
       "          (residual): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (channel_embed): Sequential(\n",
       "            (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): FeatureFusionModule(\n",
       "        (cross): CrossPath(\n",
       "          (channel_proj1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (channel_proj2): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "          (cross_attn): CrossAttention(\n",
       "            (kv1): Linear(in_features=256, out_features=512, bias=False)\n",
       "            (kv2): Linear(in_features=256, out_features=512, bias=False)\n",
       "          )\n",
       "          (end_proj1): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (end_proj2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (channel_emb): ChannelEmbed(\n",
       "          (residual): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (channel_embed): Sequential(\n",
       "            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode_head): DecoderHead(\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (linear_c4): MLP(\n",
       "      (proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "    (linear_c3): MLP(\n",
       "      (proj): Linear(in_features=160, out_features=512, bias=True)\n",
       "    )\n",
       "    (linear_c2): MLP(\n",
       "      (proj): Linear(in_features=64, out_features=512, bias=True)\n",
       "    )\n",
       "    (linear_c1): MLP(\n",
       "      (proj): Linear(in_features=32, out_features=512, bias=True)\n",
       "    )\n",
       "    (linear_fuse): Sequential(\n",
       "      (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (linear_pred): Conv2d(512, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.cmx.config import config\n",
    "from src.cmx.models.builder import EncoderDecoder as segmodel\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean', ignore_index=config.background)\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "model = segmodel(cfg=config, criterion=criterion, norm_layer=BatchNorm2d)\n",
    "\n",
    "# set the model to device and set to eval mode\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "# init weights from a pre-trained model\n",
    "model.init_weights(config, pretrained='out/log_lindenthal-camera-traps_mit_b0_pretrained_jet_dropout/checkpoint/epoch-last.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 480, 848]) torch.Size([1, 3, 480, 848])\n"
     ]
    }
   ],
   "source": [
    "# open a folder and iterate over all the images\n",
    "import os\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\"\n",
    "import os.path as osp\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "from src.utils.postprocessing import depth_to_colormap\n",
    "from src.cmx.engine.evaluator import Evaluator\n",
    "\n",
    "# set the directory\n",
    "VIDEO_ID = 'bag_20210802015851'\n",
    "rgb_dir = 'color'\n",
    "depth_dir = 'depth'\n",
    "video_dir = osp.join('data', 'lindenthal-camera-traps', 'lindenthal_coco', 'images', VIDEO_ID)\n",
    "\n",
    "# get the class colors for the mask\n",
    "colors = get_class_colors()\n",
    "# create the Evaluator object\n",
    "\n",
    "# for every image in the color folder in alphabetical order\n",
    "for rgb_fn in sorted(os.listdir(osp.join(video_dir, rgb_dir))):\n",
    "    image_id = int(rgb_fn.split('.')[0])\n",
    "    # skip every non 10th image\n",
    "    if image_id % 10 != 0 or image_id < 30:\n",
    "        continue\n",
    "    # load the images\n",
    "    depth_fn = f'{image_id:06d}.exr'\n",
    "    rgb_image = cv.imread(osp.join(video_dir, rgb_dir, rgb_fn))\n",
    "    depth_image = cv.imread(osp.join(video_dir, depth_dir, depth_fn), cv.IMREAD_UNCHANGED)\n",
    "    # save these images\n",
    "    cv.imwrite(f'{image_id:06d}_rgb.png', rgb_image)\n",
    "    # normalize the images to 0-1 in float32\n",
    "    rgb_image = cv.cvtColor(rgb_image, cv.COLOR_BGR2RGB) / 255.0\n",
    "    depth_image = depth_to_colormap(depth_image, 'jet', equalize=False)\n",
    "    cv.imwrite(f'{image_id:06d}_depth.png', depth_image)\n",
    "    depth_image = depth_image / 255.0\n",
    "    # convert to tensor\n",
    "    rgb_image = torch.from_numpy(np.ascontiguousarray(rgb_image)).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    depth_image = torch.from_numpy(np.ascontiguousarray(depth_image)).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    print(rgb_image.shape, depth_image.shape)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        pred = model(rgb_image.to(device), depth_image.to(device))\n",
    "    pred = torch.argmax(pred, dim=1).cpu().numpy().squeeze()\n",
    "\n",
    "    # save the segmentation\n",
    "    pred_fn = f'{image_id:06d}_pred.png'\n",
    "    result_img = color_mask(pred.astype(np.uint8), colors)\n",
    "    cv.imwrite(pred_fn, pred)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
